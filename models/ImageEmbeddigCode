import torch
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from tkinter import Tk, filedialog
import numpy as np

def generate_image_embedding(image_path):
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt")
    with torch.no_grad():
        embeddings = model.get_image_features(**inputs)
    # Normalize the embeddings
    embeddings = embeddings / embeddings.norm(p=2, dim=-1, keepdim=True)
    return embeddings.cpu().numpy()

def upload_image():
    Tk().withdraw()
    image_path = filedialog.askopenfilename()
    return image_path

def main():
    image_path = upload_image()
    if image_path:
        image_embedding = generate_image_embedding(image_path)
        print("Image Embedding Generated and Saved as 'IE.npy'")
        np.save("IE.npy", image_embedding)
    else:
        print("No image selected.")

if __name__ == "__main__":
    main()
