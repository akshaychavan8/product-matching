import torch
from transformers import CLIPProcessor, CLIPModel
import numpy as np

def generate_text_embedding(text):
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    inputs = processor(text=[text], return_tensors="pt", padding=True)
    with torch.no_grad():
        embeddings = model.get_text_features(**inputs)
    # Normalize the embeddings
    embeddings = embeddings / embeddings.norm(p=2, dim=-1, keepdim=True)
    return embeddings.cpu().numpy()

def main():
    text_query = input("Enter your search query: ")
    text_embedding = generate_text_embedding(text_query)
    print("Text Embedding Generated and Saved as 'TE.npy'")
    np.save("TE.npy", text_embedding)

if __name__ == "__main__":
        main()
